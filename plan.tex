%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Plan of Work and Evaluation}

We propose to structure the work into three lines of effort (Table
\ref{tab:work}).  First, there is core work on tests as first-class
entities: developing representations, core algorithm development, and
so forth.  This will be performed jointly, with a basic three year
plan consisting of first focusing on representations and code/data
test integration, then focusing on operation definitions and methods
that apply to multiple operations (e.g., using normalization or
validity preservation as a tool in composition), and finally focusing
on integrating operations into workflows such as regression testing or
test generation that are more complex than single operations, and
require extensive effort to evaluate (though we will also undertake
preliminary work on these applications to keep our methods focused on
practical ends).

Concurrently, NAU will focus on TSTL-based aspects of the work, both
integration and evaluation of operations and using data generation in
a primarily code-based testing setting.  Similarly, at Utah, an as-yet-unnamed
platform for composing compiler test cases will be developed.

\begin{table}
  \begin{tabular}{l|l|l|l}
Year       & Both Institutions             & NAU                         & Utah\\
\hline
1 & test representations;         & Python composition;           & ``little fuzzers'' for C and C++;\\
       & operation definitions         & heterogenous composition     & start C/C++ composition work\\
\hline
2 & composition heuristics;       & grammar composition;        & continue C/C++ composition;\\
       & oracle composition  & Python decomposition  & start C/C++ decomposition work\\
\hline
3 & behavior+oracle comp.; & grammar decomposition; & continue C/C++ decomposition;  \\
       & regression toolchain;  & Java decomposition   & study critical compositions \\
  & decomposition for seeding \\
\end{tabular}
\caption{Some core elements of proposed work plan}
\label{tab:work}
\end{table}

\paragraph{Year 1:}
\begin{itemize}
\item
Implement basic composition approach, evaluate increase
in test throughput, evaluate new coverage due to feature interactions
in the composed test cases.
\item
Start investigating the idea that highly sophisticated tests for very
difficult input spaces (such as C++ programs) can be generated
by starting with high-coverage test cases generated by relatively simple
``little fuzzers,'' and composing them.
\item Initial framework for composition of tests for
  \emph{heterogeneous} systems.
\end{itemize}

\paragraph{Year 2:}
\begin{itemize}
\item
Define basic automatic decomposition approach: not just test reduction, but carving a test into sub-tests that for behaviors
naturally covered together, with minimal or no loss of interaction
behavior.
\item
Produce a composition approach that takes test independence
information and other heuristics (e.g. simple bridge code and
automatic variable
renamings) into account.
\item
Work on a generic grammar-based (and raw-binary) composition tool.
\item
Start on techniques for extracting
oracles from human unit tests and composing them with automatically
generated tests, and taking property-based specification
\cite{ClaessenH00,hypothesis} in automatically-generated tests and
composing properties with human tests; attempt to automatically
(heuristically, with false positives) reject invalid tests.
\end{itemize}

\paragraph{Year 3:}
\begin{itemize}
\item
Investigate more aggressive search-based composition approaches to try
to find critical compositions of features requiring generation of new
test elements.
\item
Produce tools that can combine both behavior and oracles from human
and automatically generated tests, evaluate by improved test
effectiveness and validity of tests systems, including
hardware/software systems, test on NASA systems (PI Groce has contacts
on both MSL and upcoming small CubeSAT architecture aiming at
testability).
\item
Produce composition/decomposition aware regression tools, able to
produce custom compositions and decompositions of tests to enable
high-speed effective regression testing based on changes: combine
traditional dependency analysis with on-the-fly adjustment of test granularities.
\item Investigate ability of decomposed tests to improve performance
  of seeded test generation.
\end{itemize}


\paragraph{Evaluation:}
%
While our ability to compose and decompose test cases can be evaluated
(and we will do so, using reasonable metrics), our main goal is to
further the community's understanding of the character of defects in
real systems, and of the test cases that reveal them.
%
Thus, our most important metrics will be coverage of, and ability to
discover interesting defects in, real programs such as file systems,
embedded and cyber-physical systems, and compilers.  We have working
relationships with major projects in all of these fields (e.g., PI
Regehr is a member of the LLVM Foundation's Board of Directors and PI
Groce has already begun discussion of applications of test composition
to the Southwest Experimental Garden Array  (SEGA) \cite{SEGA,FlikkemaSEGA}).
%
Specific evaluation metrics that we will use include:
\begin{itemize}
\item Can automatically decomposed tests be as good as unit tests
  written by humans? We do not propose to evaluate this via user studies, but rather
  to determine if the maintainers of important open source projects will allow
  these test cases into their curated unit test suites.
\item Are automatically composed test cases effective in increasing
  coverage beyond the summed coverage of the test cases before
  composition?  Can they hit bugs that are the result of critical
  compositions of features that are otherwise very difficult to hit?
\item Can automatically composed test cases provide significant
increases in testing throughput?
\item Can automatically decomposed seed tests for AFL, KLEE,
  EvoSuite, and TSTL provide significant
  increases in testing effectiveness (faults detected and code
  covered) over using fewer, larger and more complex,
  seed tests?
\item Can composition and decomposition be used to improve regression
  operations, as measured by traditional measures such as average
  percent faults detected (APFD)
  \cite{APFD}?  Can it reduce test flakiness?
\end{itemize}


%%%%%%%%%%%%%%%%%
